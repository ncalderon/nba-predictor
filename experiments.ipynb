{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#pd.options.display.max_columns = None\n",
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "import model.train as train\n",
    "import model.config as model_config\n",
    "import utils\n",
    "import model.dataset.game_matchup as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gm_df = gm.load_game_matchup_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment using TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Usando max_split en TimeSeriesSplit permite dividir el dataset por cantidad de filas por lo que vamos a escoger \n",
    "solo las temporadas que tiene la misma cantiadad de partidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEASON\n",
       "2004    1230\n",
       "2005    1230\n",
       "2006    1230\n",
       "2007    1230\n",
       "2008    1230\n",
       "2009    1230\n",
       "2010    1230\n",
       "2011     990\n",
       "2012    1229\n",
       "2013    1230\n",
       "2014    1230\n",
       "2015    1230\n",
       "2016    1230\n",
       "2017    1230\n",
       "2018    1230\n",
       "Name: GAME_DATE_EST, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_df.groupby(by=\"SEASON\").count()[\"GAME_DATE_EST\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que no todas las temporadas tiene la misma cantidad de partidos esto es debido a la siguientes razones:\n",
    "\n",
    "- 2011: Los jugadores hicieron una huelga debido a no estar de acuerdo con los salarios de los mismos y el limite salarial de las franquicias.\n",
    "- 2012: Un partido entre el equipo de Boston e Indiana fue suspedindo el cual despues no fue reprogramado, y al final de la temporada se decidio ya no reprogramarlo debido a qu la clasificacion a playoff ya estaba decidida y no afectaba el resultado.\n",
    "\n",
    "Por tanto se seleccionaran solo las temporadas a partir del 2013(inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gm_df[gm_df.SEASON >= 2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de como seran dividido el dataset usando TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7380\n",
      "TRAIN: [   0    1    2 ... 1227 1228 1229] TEST: [1230 1231 1232 ... 2457 2458 2459]\n",
      "TRAIN: [1230 1231 1232 ... 2457 2458 2459] TEST: [2460 2461 2462 ... 3687 3688 3689]\n",
      "TRAIN: [2460 2461 2462 ... 3687 3688 3689] TEST: [3690 3691 3692 ... 4917 4918 4919]\n",
      "TRAIN: [3690 3691 3692 ... 4917 4918 4919] TEST: [4920 4921 4922 ... 6147 6148 6149]\n",
      "TRAIN: [4920 4921 4922 ... 6147 6148 6149] TEST: [6150 6151 6152 ... 7377 7378 7379]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=len(df.SEASON.unique())-1, max_train_size=1230)\n",
    "X, y = train.X_y_values(df, model_config.X_columns, model_config.y_columns[-1:])\n",
    "print(len(X))\n",
    "for train_index, test_index in tscv.split(X=X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2))) \n",
    "models.append(('SVM', SVC(kernel = 'linear', random_state=0))) \n",
    "models.append(('KSVM', SVC(kernel = 'rbf', random_state=0))) \n",
    "models.append(('NB', GaussianNB())) \n",
    "models.append(('DT', DecisionTreeClassifier(criterion = 'entropy', random_state=0))) \n",
    "models.append((\"RF\", RandomForestClassifier(n_estimators=500, \n",
    "                                            max_features=\"sqrt\", \n",
    "                                            max_depth=15, \n",
    "                                            n_jobs=-1, \n",
    "                                            random_state = 0)))\n",
    "models.append((\"GB\", GradientBoostingClassifier(n_estimators=500, \n",
    "                                                max_depth=15, \n",
    "                                                max_features=\"sqrt\", \n",
    "                                                random_state = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment using TimeSeriesSplit\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "train_splits = len(df.SEASON.unique())-1\n",
    "print(\"Start experiments using TimeSeriesSplit\")\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    "    tscv = TimeSeriesSplit(n_splits=train_splits, max_train_size=1230)\n",
    "    X, y = train.X_y_values(df, model_config.X_columns, model_config.y_columns[-1:])\n",
    "\n",
    "    cv_results = cross_validate(model,\n",
    "                                 X,\n",
    "                                 y.ravel(),\n",
    "                                 cv=tscv,\n",
    "                                 scoring=['balanced_accuracy', 'precision', \"recall\"])\n",
    "    \n",
    "    cv_results[\"model\"] = [name]*train_splits\n",
    "    cv_results[\"season_train\"] = df.SEASON.unique()[:-1]\n",
    "    results.append(cv_results)\n",
    "    \n",
    "    names.append(name)\n",
    "print(\"Done\")\n",
    "    \n",
    "    #print('%s %s: %f (%f)' % ('balanced_accuracy', name, cv_results[\"test_balanced_accuracy\"].mean()\n",
    "    #                          , cv_results[\"test_balanced_accuracy\"].std()))\n",
    "    #print('%s %s: %f (%f)' % (\"precision\", name, cv_results[\"test_precision\"].mean()\n",
    "    #                           , cv_results[\"test_precision\"].std()))\n",
    "    #print('%s %s: %f (%f)' % (\"recall\", name, cv_results[\"test_recall\"].mean()\n",
    "    #                           , cv_results[\"test_recall\"].std()))\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results[0])\n",
    "for idx, result in enumerate(results[1:]):\n",
    "    result_df = pd.DataFrame(result)\n",
    "    results_df = pd.concat([results_df, result_df], ignore_index=True)\n",
    "results_df.to_pickle(\"./experiments/tscv_exp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}