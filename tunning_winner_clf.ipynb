{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning model\n",
    "\n",
    "A partir de los experimentos y basado en las observaciones realizadas trabajaremos de ahora en adelante solo con los modelos: SVM y LGB.\n",
    "\n",
    "Para el entrenamiento cada modelo utilizaremos las variantes:\n",
    "\n",
    "- Train: 2 seasons ; Test: 1 season ; Ventana deslizante de: 1 season\n",
    "- Train: 3 seasons ; Test: 1 season ; Ventana deslizante de: 1 season"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "results_total = []\n",
    "utils_exp.exp_results = []\n",
    "experiment_name = f\"{exp_prefix}2_season_tunning\"\n",
    "best_models = [\n",
    "    (\"RF\", RandomForestClassifier(n_estimators=300,\n",
    "                                                max_depth=11,\n",
    "                                                n_jobs=-1,\n",
    "                                                random_state=0,\n",
    "                                                criterion='entropy',\n",
    "                                                max_features=19,\n",
    "                                                min_samples_leaf=9,\n",
    "                                 )),\n",
    "    ('SVM', SVC(kernel='linear', random_state=0,\n",
    "                              C=63.513891775842986,\n",
    "                              gamma=76.1465194934807,\n",
    "                              degree= 0.4300244876201068))\n",
    "]\n",
    "folds, train_seasons, test_seasons = sscv.split(train_size=2, test_size=1)\n",
    "X, y = train.X_y_values(df, exp_X_columns, exp_y_columns)\n",
    "#params = (experiment_name, best_models, folds, train_seasons, test_seasons, X, y)\n",
    "#names, results = utils_exp.run_experiment(*params)\n",
    "#results_total.append((experiment_name, results))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from yellowbrick.style import set_palette\n",
    "import warnings\n",
    "import io\n",
    "from sklearn import base, metrics, model_selection, preprocessing, tree\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "import yellowbrick.classifier\n",
    "\n",
    "set_palette('flatui')\n",
    "fold_last_season = folds[len(folds)-1:]\n",
    "name, model = best_models[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Explore models perfomance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "fold_last_season = folds[len(folds)-1:]\n",
    "for name, model in best_models:\n",
    "    for i, idx_data in enumerate(fold_last_season):\n",
    "        print(f\"Test season: {test_seasons[i]}\")\n",
    "        train_idx, test_idx = idx_data\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx].ravel(), y[test_idx].ravel()\n",
    "        y_true = y_test\n",
    "        fit_info = model.fit(X_train, y_train)\n",
    "\n",
    "        #with sns.plotting_context('paper'):\n",
    "        #    fig, ax = plt.subplots(figsize=(2, 2), dpi=150)\n",
    "        cm_viz = classifier.ConfusionMatrix(model, percent=True)\n",
    "        cm_viz.fit(X_train, y_train)\n",
    "        cm_viz.score(X_test, y_test)\n",
    "        cm_viz.show()\n",
    "        #cm_viz.poof()\n",
    "        #with sns.plotting_context('talk'):\n",
    "            #fig, ax = plt.subplots(figsize=(20, 20), dpi=300)\n",
    "        plt.figure(figsize=(20, 20), dpi=300)\n",
    "        fi_viz = features.FeatureImportances(model, labels=exp_X_columns, relative=False)\n",
    "        fi_viz.fit(X_train, y_train)\n",
    "        fi_viz.score(X_test, y_test)\n",
    "        #fi_viz.poof()\n",
    "        fi_viz.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ROC AUC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i, idx_data in enumerate(fold_last_season):\n",
    "    print(f\"Test season: {test_seasons[i]}\")\n",
    "    train_idx, test_idx = idx_data\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx].ravel(), y[test_idx].ravel()\n",
    "    y_true = y_test\n",
    "    fit_info = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc_score(y_true, y_pred, average='weighted')\n",
    "    print(f'roc_auc: {roc_auc_score}')\n",
    "    roc_viz = ROCAUC(model, classes=['LOSS', 'WIN'])\n",
    "    roc_viz.score(X_test, y_test)\n",
    "    roc_viz.show()\n",
    "\n",
    "    roc_viz = classifier.ClassPredictionError(model, classes=['LOSS', 'WIN'])\n",
    "    roc_viz.score(X_test, y_test)\n",
    "    roc_viz.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperopt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v_folds = folds[:-1]\n",
    "test_fold = folds[-1]\n",
    "#name, model = best_models[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hyperopt_cv(params):\n",
    "    cv_results = {\n",
    "            \"roc_auc\": []\n",
    "        }\n",
    "\n",
    "    #del params['normalize']\n",
    "    #del params['scale']\n",
    "\n",
    "    for train_idx, test_idx in v_folds:\n",
    "        X[train_idx], X[test_idx] = utils.feature_scaling(X[train_idx], X[test_idx], 5)\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx].ravel(), y[test_idx].ravel()\n",
    "        y_true = y_test\n",
    "        model = SVC(**params)\n",
    "        fit_info = model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred, average='weighted')\n",
    "        cv_results[\"roc_auc\"].append(roc_auc)\n",
    "\n",
    "    return np.mean(cv_results[\"roc_auc\"])\n",
    "\n",
    "space4svm = {\n",
    "    'C': hp.uniform('C', 0, 100),\n",
    "    'kernel': hp.choice('kernel', ['linear']),\n",
    "    'gamma': hp.uniform('gamma', 0, 100),\n",
    "    'degree': hp.uniform('degree', 0, 6)\n",
    "    #'scale': hp.choice('scale', [0, 1]),\n",
    "    #'normalize': hp.choice('normalize', [0, 1])\n",
    "}\n",
    "\n",
    "# best: {'C': 63.513891775842986, 'degree': 0.4300244876201068, 'gamma': 76.1465194934807, 'kernel': 0}\n",
    "def f(params):\n",
    "    acc = hyperopt_cv(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4svm, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print(\"best:\", best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### RandomForest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    cv_results = {\n",
    "            \"roc_auc\": []\n",
    "        }\n",
    "\n",
    "    #del params['normalize']\n",
    "    #del params['scale']\n",
    "\n",
    "    for train_idx, test_idx in v_folds:\n",
    "        X[train_idx], X[test_idx] = utils.feature_scaling(X[train_idx], X[test_idx], 5)\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx].ravel(), y[test_idx].ravel()\n",
    "        y_true = y_test\n",
    "        model = RandomForestClassifier(**params)\n",
    "        fit_info = model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred, average='weighted')\n",
    "        cv_results[\"roc_auc\"].append(roc_auc)\n",
    "\n",
    "    return np.mean(cv_results[\"roc_auc\"])\n",
    "\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,20)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 500, 50)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_leaf':  hp.choice('min_samples_leaf',  np.arange(1, 20, step=1, dtype=int)),\n",
    "    #'min_samples_split': None,\n",
    "    #'max_leaf_nodes': None\n",
    "    #'scale': hp.choice('scale', [0, 1]),\n",
    "    #'normalize': hp.choice('normalize', [0, 1])\n",
    "}\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best\n",
    "    acc = hyperopt_train_test(params)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "    print('new best:', best, params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=300, trials=trials)\n",
    "print(\"best:\", best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgboost\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    t = params['type']\n",
    "    del params['type']\n",
    "    if t == 'RF':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif t == 'SVM':\n",
    "        clf = SVC(**params)\n",
    "    elif t == 'XGB':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "    elif t == 'LGB':\n",
    "        clf = lgb.LGBMClassifier(**params)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    cv_results = {\n",
    "            \"roc_auc\": []\n",
    "        }\n",
    "\n",
    "    #del params['normalize']\n",
    "    #del params['scale']\n",
    "\n",
    "    for train_idx, test_idx in v_folds:\n",
    "        X[train_idx], X[test_idx] = utils.feature_scaling(X[train_idx], X[test_idx], 5)\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx].ravel(), y[test_idx].ravel()\n",
    "        y_true = y_test\n",
    "        fit_info = clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred, average='weighted')\n",
    "        cv_results[\"roc_auc\"].append(roc_auc)\n",
    "\n",
    "    return np.mean(cv_results[\"roc_auc\"])\n",
    "\n",
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'LGB',\n",
    "        'n_estimators': hp.choice('n_estimators2', range(100, 500, 50)),\n",
    "        'max_depth': hp.choice('max_depth2', range(1,20)),\n",
    "        'num_leaves': hp.choice('num_leaves2', np.arange( 30, 150, 1, dtype=int)),\n",
    "        'reg_alpha': hp.quniform('reg_alpha2', 0.0, 1.0, 0.1),\n",
    "        'reg_lambda': hp.quniform('reg_lambda2', 0.0, 1.0, 0.1),\n",
    "        'learning_rate': hp.loguniform('learning_rate2', np.log(0.01), np.log(0.2)),\n",
    "        'min_child_weight': hp.choice('min_child_weight2', [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4]),\n",
    "        'min_child_samples': hp.choice('min_child_samples2', np.arange( 20, 500, 5, dtype=int))\n",
    "    },\n",
    "    {\n",
    "        'type': 'SVM',\n",
    "        'C': hp.uniform('C', 0, 100),\n",
    "        'kernel': hp.choice('kernel', ['linear']),\n",
    "        'gamma': hp.uniform('gamma', 0, 100),\n",
    "        'degree': hp.uniform('degree', 0, 6)\n",
    "    },{\n",
    "        'type': 'XGB',\n",
    "        'n_estimators': hp.choice('n_estimators1', range(100, 500, 50)),\n",
    "        'max_depth': hp.choice('max_depth1', range(1,20)),\n",
    "        #'num_leaves': hp.choice('num_leaves1', np.arange( 30, 150, 1, dtype=int)),\n",
    "        'reg_alpha': hp.quniform('reg_alpha1', 0.0, 1.0, 0.1),\n",
    "        'reg_lambda': hp.quniform('reg_lambda1', 0.0, 1.0, 0.1),\n",
    "        'learning_rate': hp.loguniform('learning_rate1', np.log(0.01), np.log(0.2)),\n",
    "        'min_child_weight': hp.choice('min_child_weight1', [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4]),\n",
    "        #'min_child_samples': hp.choice('min_child_samples1', np.arange( 20, 500, 5, dtype=int)),\n",
    "    },\n",
    "#     {\n",
    "#         'type': 'RF',\n",
    "#         'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "#         'max_features': hp.choice('max_features', range(1,20)),\n",
    "#         'n_estimators': hp.choice('n_estimators', range(100, 500, 50)),\n",
    "#         'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "#         'min_samples_leaf':  hp.choice('min_samples_leaf',  np.arange(1, 20, step=1, dtype=int))\n",
    "#         #'scale': hp.choice('scale', [0, 1]),\n",
    "#         #'normalize': hp.choice('normalize', [0, 1])\n",
    "#     }\n",
    "])\n",
    "count = 0\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best, count\n",
    "    count += 1\n",
    "    acc = hyperopt_train_test(params.copy())\n",
    "    if acc > best:\n",
    "        print('new best:', acc, 'using', params['type'])\n",
    "        best = acc\n",
    "    if count % 50 == 0:\n",
    "        print('iters:', count, ', acc:', acc, 'using', params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=1000, trials=trials)\n",
    "print('best:', best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}